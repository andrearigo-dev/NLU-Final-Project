{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlu_project_ner_tagging",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyCZM5TxQfCk"
      },
      "source": [
        "# Preparing corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eDMI9nsQNS4"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dRidaSgMRsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744523f6-eaba-4c10-d8d5-5b74e2a5a678"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "drive_path = 'drive/MyDrive/Colab Notebooks/'\n",
        "sys.path.insert(0, os.path.abspath(drive_path))\n",
        "\n",
        "import conll\n",
        "\n",
        "train_set = [sent for sent in conll.read_corpus_conll(drive_path + 'data/conll/train.txt') if '-DOCSTART-' not in sent[0][0]]\n",
        "test_set = [sent for sent in conll.read_corpus_conll(drive_path + 'data/conll/test.txt') if '-DOCSTART-' not in sent[0][0]]\n",
        "\n",
        "# reshape dataset\n",
        "train_set = [[(token[0].split()[0], token[0].split()[-1]) for token in sent] for sent in train_set]\n",
        "test_set = [[(token[0].split()[0], token[0].split()[-1]) for token in sent] for sent in test_set]\n",
        "\n",
        "print(train_set[0][:4])\n",
        "print(test_set[0][:4])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('EU', 'B-ORG'), ('rejects', 'O'), ('German', 'B-MISC'), ('call', 'O')]\n",
            "[('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'B-LOC'), ('GET', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foh1djNpRflr"
      },
      "source": [
        "## Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9XFWRY4WUCV"
      },
      "source": [
        "### Define function to get vocabulary of words and tags (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJnI3VnIRy9y"
      },
      "source": [
        "# idx specifies the index of the colunm to get (0: words, -1: tags)\n",
        "def get_vocabulary(data, idx=0):\n",
        "    vocab = set()\n",
        "    for sent in data:\n",
        "        for token in sent:\n",
        "            vocab.add(token[idx])\n",
        "    return sorted(list(vocab))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNfCubaaWNMY"
      },
      "source": [
        "### Create numerical mappings for words and tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdzVR2h7Wes1"
      },
      "source": [
        "def create_mapping(vocabulary, initial=None):\n",
        "    idx = {} if initial is None else initial\n",
        "\n",
        "    idx.update(\n",
        "        {w: i + len(idx) for i, w in enumerate(vocabulary)}\n",
        "        )\n",
        "    return idx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHsAsWTzdYh4"
      },
      "source": [
        "# get vocab\n",
        "words = get_vocabulary(train_set)\n",
        "labels = get_vocabulary(train_set, -1)\n",
        "\n",
        "# word mappings\n",
        "\n",
        "# word to index\n",
        "# word index\n",
        "word2idx = create_mapping(words, initial={\"<PAD>\":0, \"<UNK>\":1})\n",
        "\n",
        "# index to word, the inverse of the previous map\n",
        "# allowed since indexes are unique\n",
        "idx2word = {v: k for k, v in word2idx.items()}\n",
        "\n",
        "# labels mappings\n",
        "\n",
        "# label to index\n",
        "label2idx = create_mapping(labels)\n",
        "\n",
        "# index to label, the inverse of the previous map\n",
        "# allowed since indexes are unique\n",
        "idx2label = {v: k for k, v in label2idx.items()}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfQ_5goQXgih"
      },
      "source": [
        "### Pad and truncate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdbb9_uoXft4"
      },
      "source": [
        "def pad_and_truncate(sequences, max_len, value):\n",
        "\n",
        "  for i, seq in enumerate(sequences):\n",
        "    l = len(seq)\n",
        "    if l > max_len:\n",
        "      # truncate\n",
        "      sequences[i] = seq[:max_len]\n",
        "    else:\n",
        "      # pad\n",
        "      delta = max_len - l\n",
        "      pad = [value for i in range(delta)]\n",
        "      seq.extend(pad)\n",
        "      sequences[i] = seq\n",
        "  \n",
        "  return sequences"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQENEbX3YnHV"
      },
      "source": [
        "Prepare in advance a function to unpad e change the format for CoNLL evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GOnvlj2Ytbj"
      },
      "source": [
        "def unpad(preds, truths):\n",
        "  refs = truths.copy()\n",
        "  if len(preds) != len(refs):\n",
        "    raise ValueError\n",
        "  \n",
        "  pp = 0\n",
        "  tt = 0\n",
        "\n",
        "  hyps = []\n",
        "  \n",
        "  for i, sent in enumerate(refs):\n",
        "    if len(sent) < len(preds[i]):\n",
        "      # sentence has been padded\n",
        "      hyps.append(preds[i][:len(sent)])\n",
        "    \n",
        "    elif len(sent) > len(preds[i]):\n",
        "      # sentence has been truncated\n",
        "      # in this case its necessary to truncate\n",
        "      # also the ground truth so that they can be\n",
        "      # compared\n",
        "      refs[i] = refs[i][:len(preds[i])]\n",
        "      hyps.append(preds[i])\n",
        "    \n",
        "    elif len(sent) == len(preds[i]):\n",
        "      hyps.append(preds[i])\n",
        "\n",
        "  return hyps, refs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqg9pktA3wIr"
      },
      "source": [
        "def format_predictions_for_conll(preds, idx2label):\n",
        "  return [[('_', idx2label.get(i)) for i in s] for s in preds]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8YiElkbtAP"
      },
      "source": [
        "## Define functions to prepare the dataset and the train step for later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgAzmMopb8kO"
      },
      "source": [
        "### Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQEQGnn2aMMs"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def prepare_train(train_set, labels, word2idx, label2idx, max_len=None):\n",
        "  # vectorize data\n",
        "  x_train_int = [[word2idx[w] for w, t in s] for s in train_set]\n",
        "  # print(\"Train textual: {}\".format(list(map(lambda x: x[0], train_set[0]))))\n",
        "  # print(\"Train encoded: {}\".format(x_train_int[0]))\n",
        "\n",
        "  # padding and truncating\n",
        "\n",
        "  # get max length\n",
        "  if max_len is None:\n",
        "    max_len = max(map(len, x_train_int))\n",
        "\n",
        "  # pad the sentences to max length\n",
        "  x_train_pad = pad_and_truncate(x_train_int, max_len, word2idx['<PAD>'])\n",
        "\n",
        "  # vectorize labels\n",
        "  y_train_int = [[label2idx[t] for w, t in s] for s in train_set]\n",
        "  y_train_pad = pad_and_truncate(y_train_int, max_len, label2idx['O'])\n",
        "\n",
        "  x_train_pad = torch.tensor(x_train_pad)\n",
        "  y_train_pad = torch.tensor(y_train_pad)\n",
        "\n",
        "  # 8 is the id of 'O'\n",
        "  # print(\"Textual: {}\".format(list(map(lambda x: x[1], train_set[0]))))\n",
        "  # print(\"Encoded & Padded: {}\".format(y_train_pad[0]))\n",
        "\n",
        "  # one-hot encoding for labels\n",
        "  y_train_ohv = F.one_hot(y_train_pad, num_classes=len(labels))\n",
        "\n",
        "  return x_train_pad, y_train_ohv.float(), max_len"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMlH7wrf530D"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pThnAZxbcE21"
      },
      "source": [
        "def prepare_test(test_set, labels, word2idx, label2idx, max_len):\n",
        "  # replace words not in training with <UNK>\n",
        "  # insert in X_test_int the index of the word if it is in the vocabulary\n",
        "  # otherwise inserts the index for <UNK>\n",
        "  x_test_int = [[word2idx.get(w, word2idx.get('<UNK>')) for w, t in s] for s in test_set]\n",
        "  x_test_pad = pad_and_truncate(x_test_int, max_len, word2idx['<PAD>'])\n",
        "\n",
        "  # replace tags not in training with 'O'\n",
        "  # same way as before\n",
        "  y_test_int = [[label2idx.get(t, label2idx.get('O')) for w, t in s] for s in test_set]\n",
        "  y_test_pad = pad_and_truncate(y_test_int, max_len, label2idx['O'])\n",
        "\n",
        "  x_test_pad = torch.tensor(x_test_pad)\n",
        "  y_test_pad = torch.tensor(y_test_pad)\n",
        "\n",
        "  # to one-hot encoding\n",
        "  y_test_ohv = F.one_hot(y_test_pad, num_classes=len(labels))\n",
        "\n",
        "  return x_test_pad, y_test_ohv.float()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKYJD5S9fSLI"
      },
      "source": [
        "## Putting all in a Dataset object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No1V129NcoL5"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# mean_len = int(sum(map(len, train_set))/len(train_set))\n",
        "# print(mean_len)\n",
        "\n",
        "X_train, Y_train, max_len = prepare_train(train_set, labels, word2idx, label2idx)\n",
        "X_test, Y_test = prepare_test(test_set, labels, word2idx, label2idx, max_len)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "test_dataset = TensorDataset(X_test, Y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd3y3EsmnNrK"
      },
      "source": [
        "# Define train step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U_W5zsK7p1nh",
        "outputId": "f1db3f4b-2565-4066-8ea7-afb8b658b91e"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtAFHYQrvDK"
      },
      "source": [
        "def train_step(X, Y, model, loss_f, optimizer):\n",
        "  model.zero_grad()\n",
        "\n",
        "  # Get model predictions\n",
        "  pred = model(X)\n",
        "\n",
        "  # Computes loss\n",
        "  loss = loss_f(pred, Y)\n",
        "\n",
        "  # Computes gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # Updates parameters and zeroes gradients\n",
        "  optimizer.step()\n",
        "\n",
        "  # Returns the loss\n",
        "  return loss.item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chDjS4pAFdZy"
      },
      "source": [
        "# Create and train a BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHssijT93nhv"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfBhv3w5p9Hp"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, pad_value):\n",
        "    super(BiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_value)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "    # with dimensionality hidden_dim.\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "    # The linear layer that maps from hidden state space to tag space\n",
        "    self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "  def forward(self, sentences):\n",
        "    # INPUT: batch size (= number of sentences) x len (= number of tokens)\n",
        "\n",
        "    # EMBEDS: # batch size x len x embedding_dim\n",
        "    # B sentences composed of L tokens, one embedding for token\n",
        "    embeds = self.word_embeddings(sentences)\n",
        "    embeds = self.dropout(embeds)\n",
        "\n",
        "    # LSTM_OUT: batch x len x hidden_dim * 2 (because it is bidirectional)\n",
        "    lstm_out, _ = self.lstm(embeds)\n",
        "\n",
        "    # TAG_SPACE: batch x len x tagset_size\n",
        "    # for each token in each sentence Linear gives a vector of scores, one for each class/label\n",
        "    tag_space = self.hidden2tag(lstm_out)\n",
        "\n",
        "    # convert to probabilities\n",
        "    tag_scores = self.softmax(tag_space)\n",
        "    \n",
        "    return tag_scores"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iaqt8S_r0F_7",
        "outputId": "0370f0e7-25b7-47da-8d9a-6d8e6ffa016a"
      },
      "source": [
        "model = BiLSTM(\n",
        "    embedding_dim=64, # embedding output\n",
        "    hidden_dim=64, # lstm output\n",
        "    vocab_size=len(words)+2,\n",
        "    tagset_size=len(labels),\n",
        "    pad_value=word2idx['<PAD>']\n",
        ").to(device)\n",
        "\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM(\n",
              "  (word_embeddings): Embedding(23625, 64, padding_idx=0)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=128, out_features=9, bias=True)\n",
              "  (softmax): Softmax(dim=2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y86D8ZLNRD4c"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayd47l53RGKS"
      },
      "source": [
        "def train_model(model, train_dataset, bs, epochs, print_every, device):\n",
        "  train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=bs,\n",
        "    shuffle=True\n",
        "    )\n",
        "  \n",
        "  loss_f = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  loss = 0\n",
        "  losses = []\n",
        "\n",
        "  tot_batches = len(train_dataloader)\n",
        "  \n",
        "  model.train()\n",
        "  for e in range(epochs):\n",
        "    processed = 0\n",
        "\n",
        "    for X_batch, Y_batch in train_dataloader:\n",
        "\n",
        "      loss = train_step(X_batch.to(device), Y_batch.to(device), model, loss_f, optimizer)\n",
        "      losses.append(loss)\n",
        "\n",
        "      processed += 1\n",
        "\n",
        "      if processed % print_every == 0:\n",
        "        print(f\"\\rEpoch:{e+1}/{epochs}, Batches: {processed}/{tot_batches}, Loss: {loss}\")\n",
        "  \n",
        "  model.eval()\n",
        "  return losses"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayAD_N_vsMvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d87108d-20b0-499f-d16a-dda5e472bb05"
      },
      "source": [
        "losses = train_model(model, train_dataset, 60, 20, 100, device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20, Batches: 100/235, Loss: 0.012809001840651035\n",
            "Epoch:1/20, Batches: 200/235, Loss: 0.010902890004217625\n",
            "Epoch:2/20, Batches: 100/235, Loss: 0.004765823017805815\n",
            "Epoch:2/20, Batches: 200/235, Loss: 0.006503804586827755\n",
            "Epoch:3/20, Batches: 100/235, Loss: 0.004286171402782202\n",
            "Epoch:3/20, Batches: 200/235, Loss: 0.0042477925308048725\n",
            "Epoch:4/20, Batches: 100/235, Loss: 0.0031228011939674616\n",
            "Epoch:4/20, Batches: 200/235, Loss: 0.0030968529172241688\n",
            "Epoch:5/20, Batches: 100/235, Loss: 0.0026768865063786507\n",
            "Epoch:5/20, Batches: 200/235, Loss: 0.0032708244398236275\n",
            "Epoch:6/20, Batches: 100/235, Loss: 0.001992212375625968\n",
            "Epoch:6/20, Batches: 200/235, Loss: 0.0020477506332099438\n",
            "Epoch:7/20, Batches: 100/235, Loss: 0.0027796290814876556\n",
            "Epoch:7/20, Batches: 200/235, Loss: 0.0018015060340985656\n",
            "Epoch:8/20, Batches: 100/235, Loss: 0.0010947983246296644\n",
            "Epoch:8/20, Batches: 200/235, Loss: 0.001471659285016358\n",
            "Epoch:9/20, Batches: 100/235, Loss: 0.001032940112054348\n",
            "Epoch:9/20, Batches: 200/235, Loss: 0.0013537806225940585\n",
            "Epoch:10/20, Batches: 100/235, Loss: 0.0006076529971323907\n",
            "Epoch:10/20, Batches: 200/235, Loss: 0.0009827890899032354\n",
            "Epoch:11/20, Batches: 100/235, Loss: 0.002295723417773843\n",
            "Epoch:11/20, Batches: 200/235, Loss: 0.0004890758427791297\n",
            "Epoch:12/20, Batches: 100/235, Loss: 0.0009509219671599567\n",
            "Epoch:12/20, Batches: 200/235, Loss: 0.0007574991905130446\n",
            "Epoch:13/20, Batches: 100/235, Loss: 0.0006468403153121471\n",
            "Epoch:13/20, Batches: 200/235, Loss: 0.0008083262946456671\n",
            "Epoch:14/20, Batches: 100/235, Loss: 0.0011986149474978447\n",
            "Epoch:14/20, Batches: 200/235, Loss: 0.000661462836433202\n",
            "Epoch:15/20, Batches: 100/235, Loss: 0.0006864415481686592\n",
            "Epoch:15/20, Batches: 200/235, Loss: 0.000900908256880939\n",
            "Epoch:16/20, Batches: 100/235, Loss: 0.0007642769487574697\n",
            "Epoch:16/20, Batches: 200/235, Loss: 0.0007816755678504705\n",
            "Epoch:17/20, Batches: 100/235, Loss: 0.0008067594608291984\n",
            "Epoch:17/20, Batches: 200/235, Loss: 0.0009297732030972838\n",
            "Epoch:18/20, Batches: 100/235, Loss: 0.0008383442182093859\n",
            "Epoch:18/20, Batches: 200/235, Loss: 0.0004929522983729839\n",
            "Epoch:19/20, Batches: 100/235, Loss: 0.00034400029107928276\n",
            "Epoch:19/20, Batches: 200/235, Loss: 0.000621450541075319\n",
            "Epoch:20/20, Batches: 100/235, Loss: 0.00045870497706346214\n",
            "Epoch:20/20, Batches: 200/235, Loss: 0.0003642919473350048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IlqqcfUZ8RGw",
        "outputId": "e1ebe783-4391-4a28-b3fd-e03c0e85fbf3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.grid()\n",
        "plt.plot(range(len(losses)), losses)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb1f43e7210>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw79h_mTfrCj"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFynmgwkHPVH"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn.metrics as mt\n",
        "\n",
        "def evaluate_model(model, X, Y, device):\n",
        "  model.eval()\n",
        "\n",
        "  predictions = None\n",
        "  truths = None\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # recover labels from one-hot encoding\n",
        "    truths = Y.argmax(dim=2)\n",
        "\n",
        "    # recover labels from probabilities\n",
        "    preds = model(X.to(device))\n",
        "    predictions = preds.argmax(dim=2)\n",
        "\n",
        "    # flatten labels\n",
        "    truths = truths.reshape(-1).cpu().numpy()\n",
        "\n",
        "    predictions = predictions.reshape(-1).cpu().numpy()\n",
        "\n",
        "    return mt.accuracy_score(truths, predictions), mt.f1_score(truths, predictions, average='macro'), preds"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58hNqbTnK10w",
        "outputId": "bc6c363c-7152-4f6f-b972-b3f142f4f051"
      },
      "source": [
        "acc, f1, preds_prob = evaluate_model(model, X_test, Y_test, device)\n",
        "print(f'Accuracy: {acc*100}, f1: {f1*100}')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.34365140995773, f1: 77.89567514339262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwZSw_eRLDtb"
      },
      "source": [
        "## CoNLL evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wI1mnIdYYZDf",
        "outputId": "dd21ef65-42f6-4309-ac5f-b6494490ff67"
      },
      "source": [
        "preds = preds_prob.argmax(dim=2).cpu().numpy()\n",
        "preds_unpadded, truncated_truths = unpad(preds, test_set)\n",
        "\n",
        "results = conll.evaluate(truncated_truths, format_predictions_for_conll(preds_unpadded, idx2label))\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.747</td>\n",
              "      <td>0.619</td>\n",
              "      <td>0.677</td>\n",
              "      <td>1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.551</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.622</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.778</td>\n",
              "      <td>0.656</td>\n",
              "      <td>0.712</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.875</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.837</td>\n",
              "      <td>1667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.759</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.726</td>\n",
              "      <td>5646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.747  0.619  0.677  1616\n",
              "MISC   0.551  0.714  0.622   702\n",
              "ORG    0.778  0.656  0.712  1661\n",
              "LOC    0.875  0.803  0.837  1667\n",
              "total  0.759  0.696  0.726  5646"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}